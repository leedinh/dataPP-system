{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "#INPUT\n",
    "df = pd.read_csv(r'input.csv')\n",
    "min_conf = 0.5\n",
    "min_sup = 0.5\n",
    "quasifiIden = ['age', 'gender', 'education', 'marital-status', 'native-country', 'race' ]\n",
    "k = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n",
      "C:\\Users\\Omen\\AppData\\Local\\Temp\\ipykernel_8764\\3557504809.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  encoded_df.insert(column,i +':'+str(j), False)\n"
     ]
    }
   ],
   "source": [
    "#FIND RULE FROM DATASET D BY USING APRIORI\n",
    "\n",
    "\n",
    "#data cleaning\n",
    "for lab, row in df.iterrows():\n",
    "    for cell in row:\n",
    "        if cell == ' ?':\n",
    "            df.drop(lab, inplace=True)\n",
    "            break\n",
    "# initializing encoded dataframe\n",
    "encoded_df = df.copy(deep=True)\n",
    "column = len(df.columns)\n",
    "for i in df.columns:\n",
    "  for j in list(set(df[i])):\n",
    "    column = len(encoded_df.columns)\n",
    "    encoded_df.insert(column,i +':'+str(j), False)\n",
    "\n",
    "# transform category data to binary\n",
    "column = len(df.columns)\n",
    "column_arr = encoded_df.columns\n",
    "i = 0\n",
    "for lab, row in df.iterrows():\n",
    "  j = 0\n",
    "  for j in range(9):\n",
    "    getValueOfCell = df.columns[j]+ ':' + str(df.iloc[i][j])\n",
    "    index = next((n for n, item in enumerate(column_arr) if item == getValueOfCell), -1)\n",
    "    encoded_df.iloc[i, index] = True\n",
    "  i += 1\n",
    "\n",
    "for i in df.columns:\n",
    "  encoded_df.drop(i, axis=1, inplace=True)\n",
    "\n",
    "frequent_itemsets = apriori(encoded_df, min_support=min_sup, use_colnames = True)\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric = \"confidence\", min_threshold = min_conf)\n",
    "rules = rules[['antecedents', 'consequents', 'support', 'confidence']]\n",
    "rules.to_csv('rules.csv', index=False) #SET OF RULE CARE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter output must have quasify attribute in the rules\n",
    "final_res = rules[['antecedents', 'consequents', 'support', 'confidence']]\n",
    "\n",
    "final_res.insert(4, 'HaveQuasifi', False)\n",
    "final_res.insert(5, 'QIrhs', False)\n",
    "\n",
    "\n",
    "for i in range(len(final_res)):\n",
    "  for ele in final_res['antecedents'][i]:\n",
    "    for item in quasifiIden:\n",
    "      if item in ele:\n",
    "        final_res['HaveQuasifi'][i] = True\n",
    "        break\n",
    "\n",
    "  for ele in final_res['consequents'][i]:\n",
    "    for item in quasifiIden:\n",
    "      if item in ele:\n",
    "        final_res['HaveQuasifi'][i] = True\n",
    "        final_res['QIrhs'][i] = True\n",
    "        break\n",
    "\n",
    "# Rcare\n",
    "final_res = final_res[final_res['HaveQuasifi']==True]\n",
    "final_res = final_res[['antecedents', 'consequents', 'support', 'confidence', 'QIrhs']]\n",
    "for i in range(len(final_res)):\n",
    "  final_res['antecedents'].iloc[i] = list(final_res.iloc[i]['antecedents'])\n",
    "  final_res['consequents'].iloc[i] = list(final_res.iloc[i]['consequents'])\n",
    "  \n",
    "final_res.to_csv('rule_care.csv', index=False) #SET OF RULE CARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM DATASET D TO OTHER FORM OF VALUE\n",
    "for i in range(len(df)):\n",
    "    for j in df.columns:\n",
    "        df[j].iloc[i]= j+':'+str(df[j].iloc[i])\n",
    "\n",
    "df.to_csv('transformed_input.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY DATA STRUCTURE FOR RULE CARE AND CALCULATE INITIAL BUDGET FOR EACH RULE\n",
    "import math\n",
    "rules = pd.read_csv('./rule_care.csv')\n",
    "rules_care = [[eval(rules['antecedents'].iloc[i]), eval(rules['consequents'].iloc[i]), rules['support'].iloc[i], rules['confidence'].iloc[i], rules['QIrhs'].iloc[i]] for i in range(len(rules))]\n",
    "\n",
    "budget = {}\n",
    "total_rows = len(df)\n",
    "for r in rules_care:\n",
    "    rule = (tuple(r[0]+r[1]))\n",
    "    if r[4]:\n",
    "        budget[rule]= round(min((r[2]-min_sup)*total_rows, math.floor(r[2]*total_rows*(r[3]-min_conf)/r[3])))\n",
    "    else:\n",
    "        budget[rule]= round(min((r[2]-min_sup)*total_rows, math.floor(r[2]*total_rows*(r[3]-min_conf)/(r[3]*(1-min_conf)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY DATA STRUCTURE FOR DATASET\n",
    "import collections\n",
    "df = pd.read_csv('./transformed_input.csv')\n",
    "subset = df[quasifiIden]\n",
    "tuples = [tuple(x) for x in subset.to_numpy()]\n",
    "freq= dict(collections.Counter(tuples)) #GROUPING EACH ROW WITH ITS KEY AS TUPLE OF QSI VALUE\n",
    "\n",
    "#SAVE THE INDEX OF EACH ROW IN DATA SET ACCORDING TO THEIR GROUP\n",
    "index_map = {}\n",
    "for index, row in df.iterrows():\n",
    "    t = tuple(row[:6])\n",
    "    if t in index_map:\n",
    "        index_map[t].append(index)\n",
    "    else:\n",
    "        index_map[t] = [index]\n",
    "        \n",
    "orgin = {}\n",
    "current = {}\n",
    "for i in index_map:\n",
    "    for j in index_map[i]:\n",
    "        orgin[j]=i\n",
    "        current[j]=i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "sg = []\n",
    "ug = []\n",
    "ug_small = []\n",
    "ug_big = []\n",
    "um = []\n",
    "\n",
    "#STATE OF EACH GROUP CAN GIVE OR BE GIVEN\n",
    "state = freq.copy()\n",
    "for i in state:\n",
    "    state[i]=0\n",
    "\n",
    "for i in freq:\n",
    "    if freq[i] >= k:\n",
    "        sg.append(i)\n",
    "    else:\n",
    "        ug.append(i)\n",
    "        if freq[i] <= k/2:\n",
    "            ug_small.append(i)\n",
    "        else:\n",
    "            ug_big.append(i)\n",
    "\n",
    "ug = sorted(ug, key=lambda x: freq[x])\n",
    "SelfG = None\n",
    "\n",
    "#COUNT THE AFFECTED RULE OF TUPLE t\n",
    "def count_Rt(rules, t):\n",
    "    res = []\n",
    "    for  r in rules:\n",
    "        check = True\n",
    "        for i in r[0]+r[1]:\n",
    "            if i not in t:\n",
    "                check = False\n",
    "                break\n",
    "        if check:\n",
    "            res.append(r)\n",
    "    return res\n",
    "            \n",
    "\n",
    "def issafe(g):\n",
    "    return freq[g]>=k or freq[g] == 0\n",
    "\n",
    "def risk(m,k):\n",
    "    # if m == 0:\n",
    "    #     return 0\n",
    "    if m >=k:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2*k - m\n",
    "\n",
    "def check_flow(i, j):\n",
    "    if i == -1 and j == 1:\n",
    "        return True\n",
    "    if i == -1 and j == 0:\n",
    "        return True\n",
    "    if i == 0 and j == 1:\n",
    "        return True\n",
    "    if i == 0 and j == 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_budget(gi,gj):\n",
    "    qij = [gi[k] for k in range(len(gi)) if gj[k]!=gi[k]]\n",
    "    rij= count_Rt(rules_care, qij)\n",
    "    for r in rij:\n",
    "            tr = tuple(r[0]+r[1])\n",
    "            if (budget[tr] <=0):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def disperse(selfg):\n",
    "    for i in index_map[selfg]:\n",
    "        index_map[orgin[i]].append(i)\n",
    "        index_map[current[i]].remove(i)\n",
    "        freq[orgin[i]]+=1\n",
    "        freq[current[i]]-=1\n",
    "        if freq[current[i]] == 0:\n",
    "            um.remove(current[i])\n",
    "        current[i]=orgin[i]\n",
    "        if freq[orgin[i]] ==1 and orgin[i] not in um:\n",
    "            um.append(orgin[i])\n",
    "    id = random.randint(0, len(sg)-1)\n",
    "    index_map[sg[id]]+=index_map[selfg]\n",
    "    index_map[selfg]=[]\n",
    "    freq[sg[id]]+=freq[selfg]\n",
    "    freq[selfg]=0\n",
    "\n",
    "def find_group_to_migrate(selg, rmg):\n",
    "    # target = None\n",
    "    # state = 0\n",
    "    #POLICY\n",
    "    #1. Nếu 1 group cho tuple thì nó sẽ luôn luôn luôn cho, và ngược lại nhận thì sẽ luôn luôn nhận\n",
    "    #2. gi -> gj (Vr thuoc Ri,gi->gj, Budget_r > 0)\n",
    "    #3. Give 2 group gi, gj. Assume gi is k-unsafe group(freq[gi] < k). The number of migrant tuples (mgrtN) is determined:\n",
    "    #    Case 1: gj is k-unsafe group(freq[gj] < k). If gi->gj, then mgrtN = min(|gi|, k - |gj|). If gi <- gj then mgrtN = min(|gj|, k - |gi|)\n",
    "    #    Case 2: gj is k-safe group(freq[gj] >= k). If gi->gj, then mgrtN = |gi|. If gi <- gj then mgrtN <= Min(k - |gi|, |gj|-k, |origin(gj)|), \n",
    "    #       when min(|origin(gj)|, |gj|-k) = 0 then gi <= gj is impossible.\n",
    "    \n",
    "    candidates = None\n",
    "    max_reduction = -100\n",
    "    for g in rmg: # UGB + USG + SG -> rate risk_after = 0\n",
    "        init_risk = risk(freq[selg],k) + risk(freq[g],k)\n",
    "        \n",
    "        if not (check_flow(state[selg], state[g]) or (check_flow(state[g], state[selg]))):\n",
    "            continue\n",
    "            \n",
    "        if not issafe(g): # g is k-unsafe group\n",
    "            # selfg -> g    \n",
    "            if check_flow(state[selg], state[g]):\n",
    "                #Check Budget selg -> g\n",
    "                if not check_budget(selg,g):\n",
    "                    continue\n",
    "                \n",
    "                mgrntN1 = min(freq[selg], k - freq[g])\n",
    "                after_risk1 = risk(freq[selg] - mgrntN1,k) + risk(freq[g] + mgrntN1,k)\n",
    "                risk_reduce1 = init_risk - after_risk1\n",
    "                \n",
    "                if after_risk1 == 0:\n",
    "                    return (g, mgrntN1, 1)\n",
    "                \n",
    "                if risk_reduce1 > max_reduction:\n",
    "                    max_reduction = risk_reduce1\n",
    "                    candidates = (g, mgrntN1, 1)\n",
    "            \n",
    "                    \n",
    "            if check_flow(state[g], state[selg]):\n",
    "            # selfg <- g \n",
    "            \n",
    "                #Check Budget g -> selfg\n",
    "                if not check_budget(g,selg):\n",
    "                    continue\n",
    "\n",
    "                mgrntN2 = min(freq[selg], k - freq[g])\n",
    "                after_risk2 = risk(freq[selg] + mgrntN2,k) + risk(freq[g] - mgrntN2,k)\n",
    "                risk_reduce2 = init_risk - after_risk2\n",
    "        \n",
    "                if after_risk2 == 0:\n",
    "                    return (g, mgrntN2, -1)\n",
    "                \n",
    "                if risk_reduce2 > max_reduction:\n",
    "                    max_reduction = risk_reduce2\n",
    "                    candidates = (g, mgrntN2, -1)\n",
    "        else:\n",
    "            if check_flow(state[g], state[selg]):\n",
    "                #Check Budget g -> selfg\n",
    "                if not check_budget(g,selg):\n",
    "                    continue\n",
    "                \n",
    "                if freq[g] == k: \n",
    "                    continue\n",
    "                mgrntN2 = min(k - freq[selg], freq[g]-k)\n",
    "                after_risk2 = risk(freq[selg] + mgrntN2,k) + risk(freq[g] - mgrntN2,k)\n",
    "                risk_reduce2 = init_risk - after_risk2\n",
    "        \n",
    "                if after_risk2 == 0:\n",
    "                    return (g, mgrntN2, -1)\n",
    "                \n",
    "                if risk_reduce2 > max_reduction:\n",
    "                    max_reduction = risk_reduce2\n",
    "                    candidates = (g, mgrntN2, -1)\n",
    "                    \n",
    "                    \n",
    "            if check_flow(state[selg], state[g]):\n",
    "                if not check_budget(selg,g):\n",
    "                    continue\n",
    "\n",
    "                mgrntN1 = freq[SelfG]\n",
    "                after_risk1 = risk(freq[selg] - mgrntN1,k) + risk(freq[g] + mgrntN1,k)\n",
    "                risk_reduce1 = init_risk - after_risk1\n",
    "                \n",
    "                if after_risk1 == 0:\n",
    "                    return (g, mgrntN1, 1)\n",
    "                \n",
    "                if risk_reduce1 > max_reduction:\n",
    "                    max_reduction = risk_reduce1\n",
    "                    candidates = (g, mgrntN1, 1)\n",
    "                        \n",
    "   \n",
    "    return candidates\n",
    "            \n",
    "                    \n",
    "            \n",
    "    \n",
    "while len(ug) > 0 or SelfG:\n",
    "        if SelfG is None:\n",
    "            SelfG = ug.pop(0)\n",
    "        if SelfG in ug_small:\n",
    "            ug_small.remove(SelfG)\n",
    "        elif SelfG in ug_big:\n",
    "            ug_big.remove(SelfG)\n",
    "        if freq[SelfG] <= k/2:\n",
    "            remaining_groups = ug_big + ug_small + sg\n",
    "        else:\n",
    "            remaining_groups = ug_small + ug_big + sg\n",
    "\n",
    "        g = find_group_to_migrate(SelfG, remaining_groups)\n",
    "        if g is None:\n",
    "            um.append(SelfG)\n",
    "            SelfG = None\n",
    "            \n",
    "        else:\n",
    "            Nmgrt = g[1]\n",
    "            #Migrate from SelG to G g[1] tuples\n",
    "            if g[2] == 1:\n",
    "                freq[SelfG] -= Nmgrt\n",
    "                freq[g[0]] += Nmgrt\n",
    "                state[g[0]] = 1\n",
    "                state[SelfG] = -1\n",
    "                for i in index_map[SelfG][:Nmgrt]:\n",
    "                    current[i]=g[0]\n",
    "                index_map[g[0]]+= index_map[SelfG][:Nmgrt]\n",
    "                index_map[SelfG] = index_map[SelfG][Nmgrt:]\n",
    "                Qij = [SelfG[i] for i in range(len(SelfG)) if g[0][i]!=SelfG[i]]\n",
    "                Ri_j= count_Rt(rules_care, Qij)\n",
    "                for r in Ri_j:\n",
    "                    tr = tuple(r[0]+r[1])\n",
    "                    budget[tr]-= 1\n",
    "                    \n",
    "            else:\n",
    "                freq[SelfG] += Nmgrt\n",
    "                freq[g[0]] -= Nmgrt\n",
    "                state[g[0]] = -1\n",
    "                state[SelfG] = +1\n",
    "                for i in index_map[g[0]][:Nmgrt]:\n",
    "                        current[i]=SelfG\n",
    "                index_map[SelfG]+= index_map[g[0]][:Nmgrt]\n",
    "                index_map[g[0]] = index_map[g[0]][Nmgrt:]\n",
    "                Qij = [g[0][i] for i in range(len(g[0])) if g[0][i]!=SelfG[i]]\n",
    "                Ri_j= count_Rt(rules_care, Qij)\n",
    "                for r in Ri_j:\n",
    "                    tr = tuple(r[0]+r[1])\n",
    "                    budget[tr]-= 1\n",
    "                \n",
    "            \n",
    "            if issafe(SelfG):\n",
    "                sg.append(SelfG)\n",
    "                if SelfG in ug:\n",
    "                    ug.remove(SelfG)\n",
    "                if SelfG in ug_big:\n",
    "                    ug_big.remove(SelfG)\n",
    "                if SelfG in ug_small:\n",
    "                    ug_small.remove(SelfG)\n",
    "                state[SelfG] = 0\n",
    "            \n",
    "            if issafe(g[0]):\n",
    "                sg.append(g[0])\n",
    "                if g[0] in ug:\n",
    "                    ug.remove(g[0])\n",
    "                if g[0] in ug_big:\n",
    "                    ug_big.remove(g[0])\n",
    "                if g[0] in ug_small:\n",
    "                    ug_small.remove(g[0])\n",
    "                state[g[0]] = 0\n",
    "        \n",
    "        \n",
    "            print(SelfG, index_map[SelfG],freq[SelfG])\n",
    "            print(g[0],index_map[g[0]],freq[g[0]])\n",
    "            \n",
    "            if issafe(SelfG) and issafe(g[0]):\n",
    "                SelfG = None\n",
    "            else:\n",
    "                if not issafe(g[0]):\n",
    "                    SelfG = g[0]\n",
    "         \n",
    "if len(um) >0:\n",
    "    for g in um:\n",
    "        disperse(g)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('./transformed_input.csv')\n",
    "for i in index_map:\n",
    "    for j in index_map[i]:\n",
    "        for k in range(len(quasifiIden)):\n",
    "            ds.iloc[j][quasifiIden[k]]=i[k]\n",
    "\n",
    "ds.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv('result.csv')\n",
    "for i in range(len(dff)):\n",
    "    for j in dff.columns:\n",
    "        val = dff.iloc[i][j].split(':')[1]\n",
    "        dff.iloc[i][j] = val\n",
    "\n",
    "        \n",
    "dff.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a303b10f3003b5f170dda42a40ebd460ec06710e04dc918f2cff4397bae5fda2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
